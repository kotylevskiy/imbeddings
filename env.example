# Required
# Hugging Face access token with read access to model weights.
HF_TOKEN=hf_put_your_token_here

# This variable is only used with Dockerfile.gpu / docker-compose.gpu.yaml
# Select a PyTorch GPU base tag from https://hub.docker.com/r/pytorch/pytorch/tags
# Use the tag only; Dockerfile.gpu resolves to "pytorch/pytorch:TAG".
# Example: 2.10.0-cuda13.0-cudnn9-runtime
PYTORCH_TAG=2.10.0-cuda13.0-cudnn9-runtime

# Device selection: auto (default), cpu, or cuda.
IMBEDDINGS_DEVICE=auto
# Optional CUDA memory cap per process (fraction of total GPU memory).
# Example: 0.5 uses up to 50% of the GPU's memory.
IMBEDDINGS_CUDA_MEMORY_FRACTION=0.5

# Max number of model bundles cached in memory.
IMBEDDINGS_MAX_LOADED_MODELS=1

# Service
# Bind host for Uvicorn inside the container/local run.
IMBEDDINGS_HOST=0.0.0.0
# Port for the API (also used for Docker port mapping).
IMBEDDINGS_PORT=8000

# Request limits
# Max images per request batch.
IMBEDDINGS_MAX_BATCH_SIZE=4
# Max decoded image dimensions (pixels).
IMBEDDINGS_MAX_IMAGE_WIDTH=1024
IMBEDDINGS_MAX_IMAGE_HEIGHT=1024
# Max image payload size in bytes.
IMBEDDINGS_MAX_IMAGE_BYTES=102400
# Timeout (seconds) for fetching remote images by URL.
IMBEDDINGS_REMOTE_IMAGE_REQUEST_TIMEOUT=10
